{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "config = {\n",
    "    \"window\": 10,\n",
    "    \"embedding_dim\": 300,\n",
    "    \"n_layers_action\": 1,\n",
    "    \"n_layers_state\": 1,\n",
    "    \"n_layers_scorer\": 1,\n",
    "    \"n_layers_lstm\": 1,\n",
    "    \"hidden_dim_action\": 64,\n",
    "    \"hidden_dim_state\": 512,\n",
    "    \"hidden_dim_scorer\": 512,\n",
    "    \"hidden_lstm\": 128,\n",
    "    \"activation\": \"relu\",\n",
    "    \"emb\": \"sum\",\n",
    "    \"hc\": None,\n",
    "    \"unq\": False,\n",
    "    \"learning_rate\": 0.0001,\n",
    "    \"env_step_limit\": 20,\n",
    "    \"seed\": 256,\n",
    "    \"max_steps\": 100000,\n",
    "    \"update_freq\": 1,\n",
    "    \"log_freq\": 500,\n",
    "    \"eval_freq\": 1000,\n",
    "    \"memory_size\": 500000,\n",
    "    \"encoder_memory_size\": 10,\n",
    "    \"save_memory\": 0.5,\n",
    "    \"memory_path\": \"./encoder_memory/\",\n",
    "    \"batch_size\": 256,\n",
    "    \"gamma\": 0.9,\n",
    "    \"clip\": 100,\n",
    "    \"game_path\": \"./scenarios\",\n",
    "    \"wrong_answer\": True,\n",
    "    \"soft_reward\": False,\n",
    "    \"reward_scale\": 1,\n",
    "    \"wording\": True,\n",
    "    \"evaluation\": \"cause\",\n",
    "    \"document\": False,\n",
    "    \"reduced\": False,\n",
    "    \"encoder_type\": \"fasttext\",\n",
    "    \"train_ratio\": 0.8,\n",
    "    \"test_ratio\": 0.1,\n",
    "    \"test_mode\": \"wording\",\n",
    "    \"save_path\": \"./models/\",\n",
    "    \"train_type\": \"normal\",\n",
    "    \"TAU\": 0.5,\n",
    "    \"pretrain\": False,\n",
    "    \"llm_assisted\": False,\n",
    "    \"use_attention\": False,\n",
    "    \"pretrained_explore\": 0.3,\n",
    "    \"reduce_scenarios\": False,\n",
    "    \"patient\": \"baby\",\n",
    "    \"penalty\": -0.01,\n",
    "}\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c51242fbb721bee5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "import json\n",
    "import torch\n",
    "import game\n",
    "import wandb\n",
    "import argparse\n",
    "import random\n",
    "random.seed(config[\"seed\"])\n",
    "import shutil\n",
    "import fasttext\n",
    "import scipy\n",
    "from scenario_helper import split_single_scenario\n",
    "from extract_scenarios import scenario_extractor\n",
    "import numpy as np\n",
    "from drrn import DRRNAgent\n",
    "import llm_helper\n",
    "import re\n",
    "from test import summarize_ep\n",
    "import pathlib\n",
    "import copy"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9b112e7df076d132"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def check_dict_structure(results,required_keys=[\"train\", \"test\", \"val\"],sub_keys=[\"score\", \"traj_score\", \"eff_score\", \"episode\"]):\n",
    "    # Check if the required keys are present in the main dictionary\n",
    "    for key in required_keys:\n",
    "        if key not in results:\n",
    "            return False\n",
    "\n",
    "    # Check if the nested dictionaries under the required keys have the required sub keys\n",
    "    for key in required_keys:\n",
    "        sub_dict = results[key]\n",
    "        if not all(sub_key in sub_dict for sub_key in sub_keys):\n",
    "            return False\n",
    "\n",
    "    return True\n",
    "def check_subkeys(sub_dict,sub_keys=[\"score\", \"traj_score\", \"eff_score\", \"episode\"]):\n",
    "    if not all(sub_key in sub_dict for sub_key in sub_keys):\n",
    "        return False\n",
    "    return True"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7cf7b164945d7946"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def evaluate_patient_eval_mode(patient, eval_mode, inference, mode_,split):\n",
    "    #################### LOAD ENVIRONMENT ####################\n",
    "    if not os.path.exists(os.path.join('./results/',eval_mode,patient)):\n",
    "        os.makedirs(os.path.join('./results/',eval_mode,patient))\n",
    "    if os.path.exists(os.path.join('./results/',eval_mode,patient,f\"{patient}_{eval_mode}_{inference}_{split}.json\")):\n",
    "        results = json.load(open(os.path.join('./results/',eval_mode,patient,f\"{patient}_{eval_mode}_{inference}_{split}.json\"),\"r\"))\n",
    "        if check_dict_structure(results,required_keys=[mode_]):\n",
    "            print(f\"Results for {patient} {eval_mode} {inference} {split} already exist\")\n",
    "            return\n",
    "        else:\n",
    "            print(f\"Results for {patient} {eval_mode} {inference} {split} is incomplete\")\n",
    "    else:\n",
    "        results = {}\n",
    "    env_train = game.Game(path=os.path.join(config[\"game_path\"], eval_mode,patient, \"train\", str(split)), env_step_limit=config[\"env_step_limit\"],\n",
    "                          wrong_answer=config[\"wrong_answer\"],\n",
    "                          emb=config[\"emb\"], hc=config[\"hc\"],\n",
    "                          embedding_dim=config[\"embedding_dim\"],\n",
    "                          wording=config[\"wording\"], evaluation=config[\"evaluation\"],\n",
    "                          random_scenarios=True,\n",
    "                          reward_scale=config[\"reward_scale\"], reduced=config[\"reduced\"],penalty=config[\"penalty\"])\n",
    "    env_train_eval = game.Game(path=os.path.join(config[\"game_path\"], eval_mode,patient, \"train\", str(split)),\n",
    "                               env_step_limit=config[\"env_step_limit\"],\n",
    "                               wrong_answer=config[\"wrong_answer\"], emb=config[\"emb\"],\n",
    "                               hc=config[\"hc\"],\n",
    "                               embedding_dim=config[\"embedding_dim\"],\n",
    "                               wording=config[\"wording\"], evaluation=config[\"evaluation\"],\n",
    "                               random_scenarios=False,\n",
    "                               reward_scale=config[\"reward_scale\"], reduced=config[\"reduced\"])\n",
    "    env_val = game.Game(path=os.path.join(config[\"game_path\"], eval_mode,patient, \"val\", str(split)), env_step_limit=config[\"env_step_limit\"],\n",
    "                        wrong_answer=config[\"wrong_answer\"], emb=config[\"emb\"],\n",
    "                        hc=config[\"hc\"],\n",
    "                        embedding_dim=config[\"embedding_dim\"],\n",
    "                        wording=config[\"wording\"], evaluation=config[\"evaluation\"],\n",
    "                        random_scenarios=False,\n",
    "                        reward_scale=config[\"reward_scale\"], reduced=config[\"reduced\"])\n",
    "    env_test = game.Game(path=os.path.join(config[\"game_path\"], eval_mode,patient, \"test\", str(split)), env_step_limit=config[\"env_step_limit\"],\n",
    "                         wrong_answer=config[\"wrong_answer\"],\n",
    "                         emb=config[\"emb\"],\n",
    "                         hc=config[\"hc\"],\n",
    "                         embedding_dim=config[\"embedding_dim\"],\n",
    "                         wording=config[\"wording\"], evaluation=config[\"evaluation\"],\n",
    "                         random_scenarios=False,\n",
    "                         reward_scale=config[\"reward_scale\"], reduced=config[\"reduced\"])\n",
    "    state_dim = env_train.get_state_len()\n",
    "    total_num_train = env_train.get_num_of_scenarios()\n",
    "    total_num_val = env_val.get_num_of_scenarios()\n",
    "    total_num_test = env_test.get_num_of_scenarios()\n",
    "    total_num = {\"train\":total_num_train,\"val\":total_num_val, \"test\":total_num_test}\n",
    "    summarizer = llm_helper.Summarizer(prompt_format=llm_helper.SummarizerPrompt2(),max_tokens=128)\n",
    "    summarizer = None\n",
    "    if inference == \"choose\":\n",
    "        topk = 5\n",
    "        chooser_format = llm_helper.GPTChooses(topk=topk)\n",
    "        chooser = llm_helper.Chooser(prompt_format=chooser_format,model=\"gpt-4-1106-preview\",max_tokens=1024)\n",
    "    elif inference == \"recommend\":\n",
    "        num_of_recs = 5\n",
    "        recer_format = llm_helper.GPTRecs(num_of_recs=num_of_recs)\n",
    "        recer = llm_helper.Recommender(prompt_format=recer_format,model=\"gpt-4-1106-preview\",max_tokens=1024)\n",
    "    elif inference == \"play\":\n",
    "        player_format = llm_helper.GPTPlays()\n",
    "        player = llm_helper.Player(prompt_format=player_format,model=\"gpt-4-1106-preview\",max_tokens=1024)\n",
    "    elif inference == \"clin_play\":\n",
    "        clin_player_format = llm_helper.CLINPlays()\n",
    "        clin_player = llm_helper.Player(prompt_format=clin_player_format,model=\"gpt-4-1106-preview\",max_tokens=1024)\n",
    "    elif inference == \"clin_choose\":\n",
    "        topk = 5\n",
    "        clin_chooser_format = llm_helper.CLINChooses(topk=topk)\n",
    "        clin_chooser = llm_helper.Chooser(prompt_format=clin_chooser_format,model=\"gpt-4-1106-preview\",max_tokens=1024)\n",
    "    elif inference == \"clin_recommend\":\n",
    "        num_of_recs = 5\n",
    "        clin_recer_format = llm_helper.CLINRecs(num_of_recs=num_of_recs)\n",
    "        clin_recer = llm_helper.Recommender(prompt_format=clin_recer_format,model=\"gpt-4-1106-preview\",max_tokens=1024)\n",
    "    elif inference == \"cor\":\n",
    "        num_of_recs = 5\n",
    "        corer_format = llm_helper.GPTChooses_or_Recs(topk=num_of_recs)\n",
    "        corer = llm_helper.Chooser_or_Recommender(prompt_format=corer_format,model=\"gpt-4-1106-preview\",max_tokens=1024)\n",
    "    else:\n",
    "        pass\n",
    "    #################### LOAD MODEL ####################\n",
    "    if inference not in [\"play\",\"clin_play\"]:\n",
    "        agent = DRRNAgent(config, state_dim)\n",
    "        model = torch.load(os.path.join(f\"./models/{patient}_{eval_mode}_{split}\", 'best_model.pt'))\n",
    "        agent.policy_network= model\n",
    "        agent.target_network = model\n",
    "    #################### EVALUATE ####################\n",
    "    for mode in [mode_]:\n",
    "        prev_exp = None\n",
    "        if mode == \"test\":\n",
    "            if inference == \"play\" or inference == \"clin_play\":\n",
    "                if \"train\" in results.keys() and \"history\" in results[\"train\"].keys():\n",
    "                    prev_exp = results[\"train\"][\"history\"]\n",
    "            else:\n",
    "                if os.path.exists(os.path.join('./results/',f\"{patient}_{eval_mode}_normal.json\")):\n",
    "                    prev_results = json.load(open(os.path.join('./results/',f\"{patient}_{eval_mode}_normal.json\"),\"r\"))\n",
    "                    if \"train\" in prev_results.keys() and \"history\" in prev_results[\"train\"].keys():\n",
    "                        prev_exp = prev_results[\"train\"][\"history\"]\n",
    "            print(prev_exp)\n",
    "        # prev_exp = None\n",
    "        #######################\n",
    "        if mode not in results.keys():\n",
    "            results[mode]={}\n",
    "        elif check_subkeys(results[mode]):\n",
    "            print(f\"Results for {patient} {eval_mode} {inference}{mode} already exist\")\n",
    "            continue\n",
    "        else:\n",
    "            results[mode]={}\n",
    "        env = env_val if mode == \"val\" else env_test if mode == \"test\" else env_train_eval\n",
    "        total_score = 0\n",
    "        total_traj_score = 0\n",
    "        total_combined = 0\n",
    "        total_eff_score = 0\n",
    "        episodes = []\n",
    "        histories = []\n",
    "        for i in range(total_num[mode]):\n",
    "            ep_results = {}\n",
    "            if os.path.exists(os.path.join('./results/',eval_mode,patient,mode,f\"{patient}_{eval_mode}_{inference}_{split}_{i}.json\")):\n",
    "                ep_results = json.load(open(os.path.join('./results/',eval_mode,patient,mode,f\"{patient}_{eval_mode}_{inference}_{split}_{i}.json\"),\"r\"))\n",
    "                if check_subkeys(ep_results,sub_keys=[\"score\", \"traj_score\", \"eff_score\", \"episode\", \"history\", \"scenario_name\"]):\n",
    "                    print(f\"Results for {patient} {eval_mode} {inference} {mode} {i} already exist\")\n",
    "                    score = ep_results[\"score\"]\n",
    "                    traj_score = ep_results[\"traj_score\"]\n",
    "                    eff_score = ep_results[\"eff_score\"]\n",
    "                    combined = ep_results[\"combined\"]\n",
    "                    episode = ep_results[\"episode\"]\n",
    "                    history = ep_results[\"history\"]\n",
    "                    scenario_name = ep_results[\"scenario_name\"]\n",
    "                    total_score += score>0\n",
    "                    total_traj_score += traj_score\n",
    "                    total_eff_score += eff_score\n",
    "                    total_combined += combined\n",
    "                    episodes.append(episode)\n",
    "                    histories.append(history)\n",
    "                    env.increase_episodes()\n",
    "                    continue\n",
    "            if not os.path.exists(os.path.join('./results/',eval_mode,patient,mode)):\n",
    "                os.makedirs(os.path.join('./results/',eval_mode,patient,mode), exist_ok=True)\n",
    "            if inference == \"choose\":\n",
    "                score, episode, traj_score, eff_score, scenario_name,history = evaluate_episode_choose(chooser,topk, agent, env,prev_exp=prev_exp,summarizer=summarizer)\n",
    "            elif inference == \"normal\":\n",
    "                score, episode, traj_score, eff_score, scenario_name,history = evaluate_episode(agent, env, policy=\"softmax\")\n",
    "            elif inference == \"recommend\":\n",
    "                score, episode, traj_score, eff_score, scenario_name,history =  evaluate_episode_rec2(recer,num_of_recs, agent, env,prev_exp=prev_exp,summarizer=summarizer)\n",
    "            elif inference == \"play\":\n",
    "                score, episode, traj_score, eff_score, scenario_name,history = evaluate_episode_play(player, env,summarizer=summarizer,prev_exp=prev_exp)\n",
    "            elif inference == \"clin_play\":\n",
    "                score, episode, traj_score, eff_score, scenario_name,history = evaluate_episode_clin_play(mode,clin_player, env, patient,prev_exp=prev_exp,summarizer=summarizer,eval_mode=eval_mode,split=split)\n",
    "\n",
    "            elif inference == \"clin_choose\":\n",
    "                score, episode, traj_score, eff_score, scenario_name,history = evaluate_episode_clin_choose(mode,clin_chooser,topk, agent, env,patient,prev_exp=prev_exp,summarizer=summarizer,eval_mode=eval_mode,split=split)\n",
    "\n",
    "            elif inference == \"clin_recommend\":\n",
    "                score, episode, traj_score, eff_score, scenario_name,history =  evaluate_episode_clin_rec(mode,clin_recer,num_of_recs, agent, env,patient,prev_exp=prev_exp,summarizer=summarizer,eval_mode=eval_mode,split=split)\n",
    "            elif inference == \"cor\":\n",
    "                score, episode, traj_score, eff_score, scenario_name,history = evaluate_episode_choose_or_rec(corer,num_of_recs, agent, env,prev_exp=prev_exp,summarizer=summarizer)\n",
    "            else:\n",
    "                raise ValueError(\"Inference mode not supported\")\n",
    "            ep_results[\"score\"] = score\n",
    "            ep_results[\"combined\"] = (score>0) * traj_score\n",
    "            ep_results[\"traj_score\"] = traj_score\n",
    "            ep_results[\"eff_score\"] = eff_score\n",
    "            ep_results[\"episode\"] = episode\n",
    "            ep_results[\"history\"] = history\n",
    "            ep_results[\"scenario_name\"] = scenario_name\n",
    "            json.dump(ep_results, open(os.path.join('./results/',eval_mode,patient,mode,f\"{patient}_{eval_mode}_{inference}_{split}_{i}.json\"),\"w\"), indent=4)\n",
    "            total_score += score>0\n",
    "            total_traj_score += traj_score\n",
    "            total_eff_score += eff_score\n",
    "            total_combined += ((score>0) * traj_score)\n",
    "            episodes.append(episode)\n",
    "            histories.append(history)\n",
    "            env.increase_episodes()\n",
    "        results[mode][\"score\"] = (total_score/total_num[mode])\n",
    "        results[mode][\"traj_score\"] = (total_traj_score/total_num[mode])\n",
    "        results[mode][\"eff_score\"] = (total_eff_score/total_num[mode])\n",
    "        results[mode][\"combined\"] = (total_combined/total_num[mode])\n",
    "        results[mode][\"episode\"] = episodes\n",
    "        results[mode][\"history\"] = histories\n",
    "\n",
    "        json.dump(results, open(os.path.join('./results/',eval_mode,patient,f\"{patient}_{eval_mode}_{inference}_{split}.json\"),\"w\"), indent=4)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e3a8132cbfd7caf"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def evaluate_episode_rec(recer, num_of_recs, agent, env, policy=\"softmax\",prev_exp=None,summarizer=None):\n",
    "    episode = []\n",
    "    step = 0\n",
    "    score = 0\n",
    "    done = False\n",
    "    agent.reset_dictionaries()\n",
    "    history = []\n",
    "    reasons = []\n",
    "    ob, valid_acts, hc = env.reset()\n",
    "    history.append(ob[1])\n",
    "    valid_subjects = env.scenario[\"subjects\"]\n",
    "    valid_topics = env.scenario[\"topics\"]\n",
    "    valid_causes = env.scenario[\"causes\"]\n",
    "    scenario_name = env.scenario[\"name\"]\n",
    "    subject = env.scenario[\"characters\"][0]\n",
    "    problem = find_phrase(ob[1])[0]\n",
    "    state = agent.create_state(update_sentence=ob, hc=hc)\n",
    "    posttest = False\n",
    "    while not done:\n",
    "        transition = [env.scenario[\"name\"], step, ob[1], ]\n",
    "        valid_ids = agent.encode_actions(valid_acts)\n",
    "        _, action_idx, action_values, _ = agent.act(\n",
    "            [state], [valid_ids], policy=policy, eval_mode=True, action_strs=valid_acts, temperature= 1)\n",
    "        if len(valid_acts)>1:\n",
    "            is_valid = False\n",
    "            tries = 0\n",
    "            while not is_valid:\n",
    "                tries += 1\n",
    "                response = recer.rec(history, subject, problem, valid_subjects, valid_topics, valid_causes, posttest=posttest,prev_exp=prev_exp,summarizer=summarizer)\n",
    "                if posttest:\n",
    "                    print(response)\n",
    "                reason,recs = response.split(\"###\")\n",
    "                reason,recs = reason.strip(\"\\n\").strip(),recs.strip(\"\\n\").strip()\n",
    "\n",
    "                parsed_responses = []\n",
    "                for x in recs.split(\"\\n\"):\n",
    "                    parsed_responses.append(parse_string_to_dict((x.split(\". \")[-1]),valid_subjects,valid_topics,valid_causes,replace_closest=tries>3))\n",
    "                recs_idxs = []\n",
    "                valid_responses = []\n",
    "                for x in parsed_responses:\n",
    "                    if x in valid_acts:\n",
    "                        recs_idxs.append(valid_acts.index(x))\n",
    "                        valid_responses.append(valid_acts[recs_idxs[-1]])\n",
    "\n",
    "                if len(recs_idxs)>0:\n",
    "                    is_valid = True\n",
    "                    act_probs = (softmax(action_values[0][recs_idxs],temperature=0.001 if posttest else 1))\n",
    "                    chosen_act_idx = torch.multinomial(act_probs, num_samples=1).item()\n",
    "                    print(reason, recs)\n",
    "                    action_str = valid_responses[chosen_act_idx]\n",
    "                    print(action_str)\n",
    "                if not is_valid and tries>3:\n",
    "                    print(\"OUT OF TRIES\")\n",
    "                    break\n",
    "            reasons.append(reason)\n",
    "        else:\n",
    "            action_str = valid_acts[0]\n",
    "            reasons.append(\"\")\n",
    "        history.append(action_str[\"sentence\"])\n",
    "        state_update, rew, done, valid_acts, hc, traj_score = env.step(ob, action_str)\n",
    "        if not done:\n",
    "            if state_update[0] == \"interaction\":\n",
    "                history.append(\".\".join(state_update[1].split(\".\")[2:]))\n",
    "            else:\n",
    "                history.append(\".\".join(state_update[1].split(\".\")[-1:]))\n",
    "        posttest = state_update[0] == \"posttest\"\n",
    "        if not done:\n",
    "            trace = env.trace\n",
    "        ob = state_update\n",
    "        score += rew\n",
    "        step += 1\n",
    "        transition += [action_str, rew, score]\n",
    "        episode.append(transition)\n",
    "        state = agent.create_state(\n",
    "            update_sentence=ob, hc=hc, previous_state=state)\n",
    "\n",
    "    traj_score = sum(\n",
    "        a in trace for a in env.scenario[\"present_actions\"]) / len(env.scenario[\"present_actions\"])\n",
    "    eff_score = sum(\n",
    "        a in trace for a in env.scenario[\"present_actions\"]) / len(trace)\n",
    "    agent.reset_dictionaries()\n",
    "    return score, episode, traj_score,eff_score, scenario_name,history"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "24c956cbb2faef63"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def evaluate_episode_rec2(recer, num_of_recs, agent, env, policy=\"softmax\",prev_exp=None,summarizer=None):\n",
    "    episode = []\n",
    "    step = 0\n",
    "    score = 0\n",
    "    done = False\n",
    "    agent.reset_dictionaries()\n",
    "    history = []\n",
    "    reasons = []\n",
    "    ob, valid_acts, hc = env.reset()\n",
    "    history.append(ob[1])\n",
    "    valid_subjects = env.scenario[\"subjects\"]\n",
    "    valid_topics = env.scenario[\"topics\"]\n",
    "    valid_causes = env.scenario[\"causes\"]\n",
    "    scenario_name = env.scenario[\"name\"]\n",
    "    subject = env.scenario[\"characters\"][0]\n",
    "    problem = find_phrase(ob[1])[0]\n",
    "    state = agent.create_state(update_sentence=ob, hc=hc)\n",
    "    posttest = False\n",
    "    while not done:\n",
    "        transition = [env.scenario[\"name\"], step, ob[1], ]\n",
    "        valid_ids = agent.encode_actions(valid_acts)\n",
    "        _, action_idx, action_values, _ = agent.act(\n",
    "            [state], [valid_ids], policy=policy, eval_mode=True, action_strs=valid_acts, temperature= 1)\n",
    "        if len(valid_acts)>1:\n",
    "            is_valid = False\n",
    "            tries = 0\n",
    "            while not is_valid:\n",
    "                tries += 1\n",
    "                response = recer.rec(history, subject, problem, valid_subjects, valid_topics, valid_causes, posttest=posttest,prev_exp=prev_exp,summarizer=summarizer)\n",
    "                if posttest:\n",
    "                    print(response)\n",
    "                reason,recs = response.split(\"###\")\n",
    "                reason,recs = reason.strip(\"\\n\").strip(),recs.strip(\"\\n\").strip()\n",
    "\n",
    "                parsed_responses = []\n",
    "                for x in recs.split(\"\\n\"):\n",
    "                    parsed_responses.append(parse_string_to_dict((x.split(\". \")[-1]),valid_subjects,valid_topics,valid_causes,replace_closest=tries>3))\n",
    "                recs_idxs = []\n",
    "                valid_responses = []\n",
    "                for x in parsed_responses:\n",
    "                    if x in valid_acts:\n",
    "                        recs_idxs.append(valid_acts.index(x))\n",
    "                        valid_responses.append(valid_acts[recs_idxs[-1]])\n",
    "\n",
    "                if len(recs_idxs)>0:\n",
    "                    if posttest:\n",
    "                        recs_idxs = [recs_idxs[0]]\n",
    "                    is_valid = True\n",
    "                    act_probs = (softmax(action_values[0][recs_idxs],temperature=0.001 if posttest else 1))\n",
    "                    chosen_act_idx = torch.multinomial(act_probs, num_samples=1).item()\n",
    "                    print(reason, recs)\n",
    "                    action_str = valid_responses[chosen_act_idx]\n",
    "                    print(action_str)\n",
    "                if not is_valid and tries>3:\n",
    "                    print(\"OUT OF TRIES\")\n",
    "                    break\n",
    "            reasons.append(reason)\n",
    "        else:\n",
    "            action_str = valid_acts[0]\n",
    "            reasons.append(\"\")\n",
    "        history.append(action_str[\"sentence\"])\n",
    "        state_update, rew, done, valid_acts, hc, traj_score = env.step(ob, action_str)\n",
    "        if not done:\n",
    "            if state_update[0] == \"interaction\":\n",
    "                history.append(\".\".join(state_update[1].split(\".\")[2:]))\n",
    "            else:\n",
    "                history.append(\".\".join(state_update[1].split(\".\")[-1:]))\n",
    "        posttest = state_update[0] == \"posttest\"\n",
    "        if not done:\n",
    "            trace = env.trace\n",
    "        ob = state_update\n",
    "        score += rew\n",
    "        step += 1\n",
    "        transition += [action_str, rew, score]\n",
    "        episode.append(transition)\n",
    "        state = agent.create_state(\n",
    "            update_sentence=ob, hc=hc, previous_state=state)\n",
    "\n",
    "    traj_score = sum(\n",
    "        a in trace for a in env.scenario[\"present_actions\"]) / len(env.scenario[\"present_actions\"])\n",
    "    eff_score = sum(\n",
    "        a in trace for a in env.scenario[\"present_actions\"]) / len(trace)\n",
    "    agent.reset_dictionaries()\n",
    "    return score, episode, traj_score,eff_score, scenario_name,history"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dbf06b3fc4a804e5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def evaluate_episode_clin_rec(mode,recer, num_of_recs, agent, env,patient,eval_mode, policy=\"softmax\",prev_exp=None,summarizer=None,split=0):\n",
    "    score = 0\n",
    "    for ep in range(3):\n",
    "        if score == 1:\n",
    "            break\n",
    "        episode = []\n",
    "        step = 0\n",
    "        score = 0\n",
    "        done = False\n",
    "        agent.reset_dictionaries()\n",
    "        history = []\n",
    "        reasons = []\n",
    "        learning_ids = []\n",
    "        saved_history = []\n",
    "        history_update = {}\n",
    "        ob, valid_acts, hc = env.reset()\n",
    "        history.append(ob[1])\n",
    "        valid_subjects = env.scenario[\"subjects\"]\n",
    "        valid_topics = env.scenario[\"topics\"]\n",
    "        valid_causes = env.scenario[\"causes\"]\n",
    "        scenario_name = env.scenario[\"name\"]\n",
    "        subject = env.scenario[\"characters\"][0]\n",
    "        problem = find_phrase(ob[1])[0]\n",
    "        state = agent.create_state(update_sentence=ob, hc=hc)\n",
    "        posttest = False\n",
    "        TaskDescription = f\"Find the cause behind the {subject}'s {problem}\"\n",
    "        task, sub_task = patient, scenario_name\n",
    "        save_path = f\"./results/memory/{eval_mode}/{mode}/{split}/rec/{task}/{sub_task}\"\n",
    "        if not os.path.exists(save_path):\n",
    "            pathlib.Path(save_path).mkdir(parents=True, exist_ok=True)\n",
    "            episodeIdx = 0\n",
    "        else:\n",
    "            episodeIdx = len(os.listdir(save_path))\n",
    "        episodeIdx = max(episodeIdx, ep)\n",
    "        if episodeIdx > 0:\n",
    "            summary = json.load(open(f\"{save_path}/{episodeIdx - 1}.json\", \"r\"))[\"summary\"]\n",
    "        else:\n",
    "            summary = \"\"\n",
    "        file_name = f\"{save_path}/{episodeIdx}.json\"\n",
    "        while not done:\n",
    "            transition = [env.scenario[\"name\"], step, ob[1], ]\n",
    "            valid_ids = agent.encode_actions(valid_acts)\n",
    "            _, action_idx, action_values, _ = agent.act(\n",
    "                [state], [valid_ids], policy=policy, eval_mode=True, action_strs=valid_acts, temperature= 1)\n",
    "            if len(valid_acts)>1:\n",
    "                is_valid = False\n",
    "                tries = 0\n",
    "                while not is_valid:\n",
    "                    tries += 1\n",
    "                    response = recer.rec(history, subject, problem, valid_subjects, valid_topics, valid_causes, summary, posttest=posttest,prev_exp=prev_exp,summarizer=summarizer)\n",
    "                    print(response)\n",
    "\n",
    "                    if posttest:\n",
    "                        print(response)\n",
    "                    try:\n",
    "                        ### split and remove empty strings and spaces\n",
    "                        response_split = []\n",
    "                        for x in response.split(\"$$$\"):\n",
    "                            x = x.strip(\"\\n\").strip()\n",
    "                            if len(x)>0:\n",
    "                                response_split.append(x)\n",
    "                        if len(response_split) == 2:\n",
    "                            learning_id,response = response_split\n",
    "                        else:\n",
    "                            learning_id,response = \"\",response_split[0]\n",
    "                    except Exception as e:\n",
    "                        print(e)\n",
    "                        print(response)\n",
    "                        continue\n",
    "                    learning_id = learning_id.strip(\"\\n\").strip()\n",
    "                    try:\n",
    "                        reason,recs = response.split(\"###\")\n",
    "                    except Exception as e:\n",
    "                        print(e)\n",
    "                        print(response)\n",
    "                        continue\n",
    "                    reason,recs = reason.strip(\"\\n\").strip(),recs.strip(\"\\n\").strip()\n",
    "\n",
    "                    parsed_responses = []\n",
    "                    for x in recs.split(\"\\n\"):\n",
    "                        parsed_responses.append(parse_string_to_dict((x.split(\". \")[-1]),valid_subjects,valid_topics,valid_causes,replace_closest=tries>3))\n",
    "                    recs_idxs = []\n",
    "                    valid_responses = []\n",
    "                    for x in parsed_responses:\n",
    "                        if x in valid_acts:\n",
    "                            recs_idxs.append(valid_acts.index(x))\n",
    "                            valid_responses.append(valid_acts[recs_idxs[-1]])\n",
    "\n",
    "                    if len(recs_idxs)>0:\n",
    "                        is_valid = True\n",
    "                        act_probs = (softmax(action_values[0][recs_idxs],temperature=0.001 if posttest else 1))\n",
    "                        chosen_act_idx = torch.multinomial(act_probs, num_samples=1).item()\n",
    "                        print(reason, recs)\n",
    "                        action_str = valid_responses[chosen_act_idx]\n",
    "                        print(action_str)\n",
    "                    if not is_valid and tries>3:\n",
    "                        print(\"OUT OF TRIES\")\n",
    "                        break\n",
    "            else:\n",
    "                action_str = valid_acts[0]\n",
    "            history_update[\"observation\"] = history[-1]\n",
    "            history_update[\"rationale\"] = reason\n",
    "            history_update[\"action\"] = action_str[\"sentence\"]\n",
    "            learning_ids.append(learning_id)\n",
    "            reasons.append(reason)\n",
    "            history.append(action_str[\"sentence\"])\n",
    "            saved_history.append(copy.deepcopy(history_update))\n",
    "            state_update, rew, done, valid_acts, hc, traj_score = env.step(ob, action_str)\n",
    "            if not done:\n",
    "                if state_update[0] == \"interaction\":\n",
    "                    history.append(\".\".join(state_update[1].split(\".\")[2:]))\n",
    "                else:\n",
    "                    history.append(\".\".join(state_update[1].split(\".\")[-1:]))\n",
    "            posttest = state_update[0] == \"posttest\"\n",
    "            if not done:\n",
    "                trace = env.trace\n",
    "            ob = state_update\n",
    "            score += rew\n",
    "            step += 1\n",
    "            transition += [action_str, rew, score]\n",
    "            episode.append(transition)\n",
    "            state = agent.create_state(\n",
    "                update_sentence=ob, hc=hc, previous_state=state)\n",
    "\n",
    "        traj_score = sum(\n",
    "            a in trace for a in env.scenario[\"present_actions\"]) / len(env.scenario[\"present_actions\"])\n",
    "        eff_score = sum(\n",
    "            a in trace for a in env.scenario[\"present_actions\"]) / len(trace)\n",
    "        agent.reset_dictionaries()\n",
    "        env.reset()\n",
    "        data = dict()\n",
    "        data[\"taskDescription\"] = TaskDescription\n",
    "        data[\"episodeIdx\"] = episodeIdx\n",
    "        data[\"history\"] = saved_history\n",
    "        data[\"finalScore\"] = score\n",
    "        data[\"finalTrajScore\"] = traj_score\n",
    "        data[\"finalEffScore\"] = eff_score\n",
    "        print(data)\n",
    "        json.dump(data, open(file_name, \"w\"))\n",
    "        if score == 1:\n",
    "            break\n",
    "        o= summarize_ep(task, sub_task,inference=\"rec\",mode=mode,eval_mode=eval_mode,split=split)\n",
    "    return score, episode, traj_score,eff_score, scenario_name,history"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f5e7e01ce6d309f6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def evaluate_episode_clin_choose(mode,chooser, topk, agent, env,patient,eval_mode, policy=\"softmax\",prev_exp=None,summarizer=None,split=0):\n",
    "    score = 0\n",
    "    for ep in range(3):\n",
    "        if score == 1:\n",
    "            break\n",
    "        episode = []\n",
    "        step = 0\n",
    "        score = 0\n",
    "        done = False\n",
    "        agent.reset_dictionaries()\n",
    "        history = []\n",
    "        reasons = []\n",
    "        learning_ids = []\n",
    "        saved_history = []\n",
    "        history_update = {}\n",
    "        ob, valid_acts, hc = env.reset()\n",
    "        history.append(ob[1])\n",
    "        scenario_name = env.scenario[\"name\"]\n",
    "        subject = env.scenario[\"characters\"][0]\n",
    "        problem = find_phrase(ob[1])[0]\n",
    "        state = agent.create_state(update_sentence=ob, hc=hc)\n",
    "        posttest = False\n",
    "        TaskDescription = f\"Find the cause behind the {subject}'s {problem}\"\n",
    "        task, sub_task = patient, scenario_name\n",
    "        save_path = f\"./results/memory/{eval_mode}/{mode}/{split}/choose/{task}/{sub_task}\"\n",
    "        if not os.path.exists(save_path):\n",
    "            pathlib.Path(save_path).mkdir(parents=True, exist_ok=True)\n",
    "            episodeIdx = 0\n",
    "        else:\n",
    "            episodeIdx = len(os.listdir(save_path))\n",
    "        episodeIdx = max(episodeIdx, ep)\n",
    "        if episodeIdx > 0:\n",
    "            summary = json.load(open(f\"{save_path}/{episodeIdx - 1}.json\", \"r\"))[\"summary\"]\n",
    "        else:\n",
    "            summary = \"\"\n",
    "        file_name = f\"{save_path}/{episodeIdx}.json\"\n",
    "        while not done:\n",
    "            transition = [env.scenario[\"name\"], step, ob[1], ]\n",
    "            valid_ids = agent.encode_actions(valid_acts)\n",
    "            _, action_idx, action_values, _ = agent.act(\n",
    "                [state], [valid_ids], policy=policy, eval_mode=True, action_strs=valid_acts, temperature= 1)\n",
    "            sorted_idxs = np.argsort(action_values[0].detach().cpu().numpy())\n",
    "            if not posttest:\n",
    "                choices_idxs = sorted_idxs[-1:-topk-1:-1]\n",
    "            else:\n",
    "                choices_idxs = sorted_idxs[-1:-3:-1]\n",
    "            choices = [valid_acts[i][\"sentence\"] for i in choices_idxs]\n",
    "            print(choices)\n",
    "            if len(valid_acts)>1:\n",
    "                is_valid = False\n",
    "                tries = 0\n",
    "                while not is_valid:\n",
    "                    tries += 1\n",
    "                    if not is_valid and tries>3:\n",
    "                        print(choices)\n",
    "                        print(chosen_action)\n",
    "                        print(reason)\n",
    "                        print('Out of tries')\n",
    "                        chosen_action = 1\n",
    "                        break\n",
    "                    response = chooser.choose(history, subject, problem, choices,summary, posttest=posttest,prev_exp=prev_exp,summarizer=summarizer)\n",
    "                    response_split = []\n",
    "                    for x in response.split(\"$$$\"):\n",
    "                        x = x.strip(\"\\n\").strip()\n",
    "                        if len(x)>0:\n",
    "                            response_split.append(x)\n",
    "                    if len(response_split) == 2:\n",
    "                        learning_id,response = response_split\n",
    "                    else:\n",
    "                        learning_id,response = \"\",response_split[0]\n",
    "                    learning_id = learning_id.strip(\"\\n\").strip()\n",
    "                    try:\n",
    "                        reason,chosen_action = response.split(\"###\")\n",
    "                    except Exception as e:\n",
    "                        print(e)\n",
    "                        print(response)\n",
    "                        continue\n",
    "                    reason,chosen_action = reason.strip(\"\\n\").strip(),chosen_action.strip(\"\\n\").strip()\n",
    "                    if chosen_action.isnumeric():\n",
    "                        chosen_action = int(chosen_action)\n",
    "                        if chosen_action<=len(choices_idxs) and chosen_action>0:\n",
    "                            chosen_action = chosen_action\n",
    "                            reason = reason\n",
    "                            is_valid = True\n",
    "                reasons.append(reason)\n",
    "                print(chosen_action)\n",
    "                print(reason)\n",
    "            else:\n",
    "                chosen_action = 1\n",
    "                reason = \"\"\n",
    "            action_str = (valid_acts[choices_idxs[chosen_action-1]])\n",
    "            history_update[\"observation\"] = history[-1]\n",
    "            history_update[\"rationale\"] = reason\n",
    "            history_update[\"action\"] = action_str[\"sentence\"]\n",
    "            learning_ids.append(learning_id)\n",
    "            reasons.append(reason)\n",
    "            history.append(action_str[\"sentence\"])\n",
    "            saved_history.append(copy.deepcopy(history_update))\n",
    "            state_update, rew, done, valid_acts, hc, traj_score = env.step(ob, action_str)\n",
    "            if not done:\n",
    "                if state_update[0] == \"interaction\":\n",
    "                    history.append(\".\".join(state_update[1].split(\".\")[2:]))\n",
    "                else:\n",
    "                    history.append(\".\".join(state_update[1].split(\".\")[-1:]))\n",
    "            posttest = state_update[0] == \"posttest\"\n",
    "            if not done:\n",
    "                trace = env.trace\n",
    "            ob = state_update\n",
    "            score += rew\n",
    "            step += 1\n",
    "            transition += [action_str, rew, score]\n",
    "            episode.append(transition)\n",
    "            state = agent.create_state(\n",
    "                update_sentence=ob, hc=hc, previous_state=state)\n",
    "        traj_score = sum(\n",
    "            a in trace for a in env.scenario[\"present_actions\"]) / len(env.scenario[\"present_actions\"])\n",
    "        eff_score = sum(\n",
    "            a in trace for a in env.scenario[\"present_actions\"]) / len(trace)\n",
    "        agent.reset_dictionaries()\n",
    "        env.reset()\n",
    "        data = dict()\n",
    "        data[\"taskDescription\"] = TaskDescription\n",
    "        data[\"episodeIdx\"] = episodeIdx\n",
    "        data[\"history\"] = saved_history\n",
    "        data[\"finalScore\"] = score\n",
    "        data[\"finalTrajScore\"] = traj_score\n",
    "        data[\"finalEffScore\"] = eff_score\n",
    "        print(data)\n",
    "        json.dump(data, open(file_name, \"w\"))\n",
    "        if score == 1:\n",
    "            break\n",
    "        o= summarize_ep(task, sub_task,inference=\"choose\",mode=mode,eval_mode=eval_mode,split=split)\n",
    "    return score, episode, traj_score, eff_score, scenario_name,history"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "61a078ba8243f53c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "def evaluate_episode_clin_play(mode,clin_player, env, patient,eval_mode,prev_exp=None,summarizer=None,split=0):\n",
    "    score = 0\n",
    "    for ep in range(3):\n",
    "        if score == 1:\n",
    "            break\n",
    "        episode = []\n",
    "        step = 0\n",
    "        score = 0\n",
    "        done = False\n",
    "        history = []\n",
    "        reasons = []\n",
    "        learning_ids = []\n",
    "        saved_history = []\n",
    "        history_update = {}\n",
    "        ob, valid_acts, hc = env.reset()\n",
    "        history.append(ob[1])\n",
    "        valid_subjects = env.scenario[\"subjects\"]\n",
    "        valid_topics = env.scenario[\"topics\"]\n",
    "        valid_causes = env.scenario[\"causes\"]\n",
    "        scenario_name = env.scenario[\"name\"]\n",
    "        subject = env.scenario[\"characters\"][0]\n",
    "        problem = find_phrase(ob[1])[0]\n",
    "        posttest = False\n",
    "        TaskDescription = f\"Find the cause behind the {subject}'s {problem}\"\n",
    "        task, sub_task = patient, scenario_name\n",
    "        save_path = f\"./results/memory/{eval_mode}/{mode}/{split}/play/{task}/{sub_task}\"\n",
    "        if not os.path.exists(save_path):\n",
    "            pathlib.Path(save_path).mkdir(parents=True, exist_ok=True)\n",
    "            episodeIdx = 0\n",
    "        else:\n",
    "            episodeIdx = len(os.listdir(save_path))\n",
    "        episodeIdx = max(episodeIdx, ep)\n",
    "        if episodeIdx > 0:\n",
    "            summary = json.load(open(f\"{save_path}/{episodeIdx - 1}.json\", \"r\"))[\"summary\"]\n",
    "        else:\n",
    "            summary = \"\"\n",
    "        file_name = f\"{save_path}/{episodeIdx}.json\"\n",
    "        while not done:\n",
    "            transition = [env.scenario[\"name\"], step, ob[1], ]\n",
    "            if len(valid_acts)>1:\n",
    "                is_valid = False\n",
    "                tries = 0\n",
    "                while not is_valid:\n",
    "                    tries += 1\n",
    "                    response = clin_player.play(history, subject, problem, valid_subjects, valid_topics, valid_causes,summary, posttest=posttest,prev_exp=prev_exp,summarizer=summarizer)\n",
    "                    response_split = []\n",
    "                    for x in response.split(\"$$$\"):\n",
    "                        x = x.strip(\"\\n\").strip()\n",
    "                        if len(x)>0:\n",
    "                            response_split.append(x)\n",
    "                    if len(response_split) == 2:\n",
    "                        learning_id,response = response_split\n",
    "                    else:\n",
    "                        learning_id,response = \"\",response_split[0]\n",
    "                    learning_id = learning_id.strip(\"\\n\").strip()\n",
    "                    try:\n",
    "                        reason,action = response.split(\"###\")\n",
    "                    except Exception as e:\n",
    "                        print(e)\n",
    "                        print(response)\n",
    "                        reason = \"\"\n",
    "                        action = response\n",
    "                    reason,action = reason.strip(\"\\n\").strip(),action.strip(\"\\n\").strip()\n",
    "                    parsed_responses = []\n",
    "                    for x in action.split(\"\\n\"):\n",
    "                        parsed_responses.append(parse_string_to_dict((x.split(\". \")[-1]),valid_subjects,valid_topics,valid_causes,replace_closest=tries>3))\n",
    "                    valid_responses = []\n",
    "                    for x in parsed_responses:\n",
    "                        if x in valid_acts:\n",
    "                            valid_responses.append(x)\n",
    "\n",
    "                    if len(valid_responses)>0:\n",
    "                        is_valid = True\n",
    "                        action_str = valid_responses[0]\n",
    "                        print(action_str)\n",
    "                    else:\n",
    "                        print(\"No valid responses\")\n",
    "                        print(action)\n",
    "                        print(parsed_responses)\n",
    "                        print(len(valid_acts))\n",
    "                    if not is_valid and tries>3:\n",
    "                        print(\"OUT OF TRIES\")\n",
    "                        break\n",
    "                history_update[\"observation\"] = history[-1]\n",
    "                history_update[\"rationale\"] = reason\n",
    "                history_update[\"action\"] = action_str[\"sentence\"]\n",
    "                learning_ids.append(learning_id)\n",
    "                reasons.append(reason)\n",
    "                history.append(action_str[\"sentence\"])\n",
    "                saved_history.append(copy.deepcopy(history_update))\n",
    "            else:\n",
    "                action_str = valid_acts[0]\n",
    "                history.append(action_str[\"sentence\"])\n",
    "            state_update, rew, done, valid_acts, hc, traj_score = env.step(ob, action_str)\n",
    "            if not done:\n",
    "                if state_update[0] == \"interaction\":\n",
    "                    history.append(\".\".join(state_update[1].split(\".\")[2:]))\n",
    "                else:\n",
    "                    history.append(\".\".join(state_update[1].split(\".\")[-1:]))\n",
    "            posttest = state_update[0] == \"posttest\"\n",
    "            if not done:\n",
    "                trace = env.trace\n",
    "            ob = state_update\n",
    "            score += rew\n",
    "            step += 1\n",
    "            transition += [action_str, rew, score]\n",
    "            episode.append(transition)\n",
    "        traj_score = sum(\n",
    "        a in trace for a in env.scenario[\"present_actions\"]) / len(env.scenario[\"present_actions\"])\n",
    "        eff_score = sum(\n",
    "        a in trace for a in env.scenario[\"present_actions\"]) / len(trace)\n",
    "        env.reset()\n",
    "        data = dict()\n",
    "        data[\"taskDescription\"] = TaskDescription\n",
    "        data[\"episodeIdx\"] = episodeIdx\n",
    "        data[\"history\"] = saved_history\n",
    "        data[\"finalScore\"] = score\n",
    "        data[\"finalTrajScore\"] = traj_score\n",
    "        data[\"finalEffScore\"] = eff_score\n",
    "        print(data)\n",
    "        json.dump(data, open(file_name, \"w\"))\n",
    "        if score == 1:\n",
    "            break\n",
    "        o= summarize_ep(task, sub_task,inference=\"play\",mode=mode,eval_mode=eval_mode,split=split)\n",
    "    return score, episode, traj_score, eff_score, scenario_name, history"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a42001f96907ab46"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def evaluate_episode_play(player, env,summarizer=None, prev_exp=None):\n",
    "    episode = []\n",
    "    step = 0\n",
    "    score = 0\n",
    "    done = False\n",
    "    history = []\n",
    "    reasons = []\n",
    "    ob, valid_acts, hc = env.reset()\n",
    "    history.append(ob[1])\n",
    "    valid_subjects = env.scenario[\"subjects\"]\n",
    "    valid_topics = env.scenario[\"topics\"]\n",
    "    valid_causes = env.scenario[\"causes\"]\n",
    "    scenario_name = env.scenario[\"name\"]\n",
    "    subject = env.scenario[\"characters\"][0]\n",
    "    problem = find_phrase(ob[1])[0]\n",
    "    posttest = False\n",
    "    while not done:\n",
    "        transition = [env.scenario[\"name\"], step, ob[1], ]\n",
    "        if len(valid_acts)>1:\n",
    "            is_valid = False\n",
    "            tries = 0\n",
    "            while not is_valid:\n",
    "                tries += 1\n",
    "                response = player.play(history, subject, problem, valid_subjects, valid_topics, valid_causes, posttest=posttest,prev_exp=prev_exp,summarizer=summarizer)\n",
    "                try:\n",
    "                    reason,action = response.split(\"###\")\n",
    "                except Exception as e:\n",
    "                    print(e)\n",
    "                    print(response)\n",
    "                    reason = \"\"\n",
    "                    action = response\n",
    "                reason,action = reason.strip(\"\\n\").strip(),action.strip(\"\\n\").strip()\n",
    "\n",
    "                parsed_responses = []\n",
    "                for x in action.split(\"\\n\"):\n",
    "                    parsed_responses.append(parse_string_to_dict((x.split(\". \")[-1]),valid_subjects,valid_topics,valid_causes,replace_closest=tries>3))\n",
    "                valid_responses = []\n",
    "                for x in parsed_responses:\n",
    "                    if x in valid_acts:\n",
    "                        valid_responses.append(x)\n",
    "\n",
    "                if len(valid_responses)>0:\n",
    "                    is_valid = True\n",
    "                    action_str = valid_responses[0]\n",
    "                    print(action_str)\n",
    "                else:\n",
    "                    print(\"No valid responses\")\n",
    "                    print(action)\n",
    "                    print(parsed_responses)\n",
    "                    print(len(valid_acts))\n",
    "                if not is_valid and tries>3:\n",
    "                    print(\"OUT OF TRIES\")\n",
    "                    break\n",
    "            reasons.append(reason)\n",
    "            history.append(action_str[\"sentence\"])\n",
    "        else:\n",
    "            action_str = valid_acts[0]\n",
    "            history.append(action_str[\"sentence\"])\n",
    "        state_update, rew, done, valid_acts, hc, traj_score = env.step(ob, action_str)\n",
    "        if not done:\n",
    "            if state_update[0] == \"interaction\":\n",
    "                history.append(\".\".join(state_update[1].split(\".\")[2:]))\n",
    "            else:\n",
    "                history.append(\".\".join(state_update[1].split(\".\")[-1:]))\n",
    "        posttest = state_update[0] == \"posttest\"\n",
    "        if not done:\n",
    "            trace = env.trace\n",
    "        ob = state_update\n",
    "        score += rew\n",
    "        step += 1\n",
    "        transition += [action_str, rew, score]\n",
    "        episode.append(transition)\n",
    "\n",
    "    traj_score = sum(\n",
    "        a in trace for a in env.scenario[\"present_actions\"]) / len(env.scenario[\"present_actions\"])\n",
    "    eff_score = sum(\n",
    "        a in trace for a in env.scenario[\"present_actions\"]) / len(trace)\n",
    "    return score, episode, traj_score,eff_score, scenario_name,history"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bd70ebd5e5ba5b36"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def evaluate_episode(agent, env, policy):\n",
    "    episode = []\n",
    "    history = []\n",
    "    step = 0\n",
    "    score = 0\n",
    "    done = False\n",
    "    agent.reset_dictionaries()\n",
    "    ob, valid_acts, hc = env.reset()\n",
    "    history.append(ob[1])\n",
    "    scenario_name = env.scenario[\"name\"]\n",
    "    state = agent.create_state(update_sentence=ob, hc=hc)\n",
    "    while not done:\n",
    "        transition = [env.scenario[\"name\"], step, ob[1], ]\n",
    "        valid_ids = agent.encode_actions(valid_acts)\n",
    "        _, action_idx, action_values, _ = agent.act(\n",
    "            [state], [valid_ids], policy=policy, eval_mode=True, action_strs=valid_acts)\n",
    "        action_idx = action_idx[0]\n",
    "        action_values = action_values[0]\n",
    "        action_str = valid_acts[action_idx]\n",
    "        state_update, rew, done, valid_acts, hc, traj_score = env.step(ob, action_str)\n",
    "        if not done:\n",
    "            trace = env.trace\n",
    "        history.append(action_str[\"sentence\"])\n",
    "        if not done:\n",
    "            if state_update[0] == \"interaction\":\n",
    "                history.append(\".\".join(state_update[1].split(\".\")[2:]))\n",
    "            else:\n",
    "                history.append(\".\".join(state_update[1].split(\".\")[-1:]))\n",
    "        ob = state_update\n",
    "        score += rew\n",
    "        step += 1\n",
    "        transition += [action_str, rew, score]\n",
    "        episode.append(transition)\n",
    "        state = agent.create_state(\n",
    "            update_sentence=ob, hc=hc, previous_state=state)\n",
    "    traj_score = sum(\n",
    "        a in trace for a in env.scenario[\"present_actions\"]) / len(env.scenario[\"present_actions\"])\n",
    "    eff_score = sum(\n",
    "        a in trace for a in env.scenario[\"present_actions\"]) / len(trace)\n",
    "    agent.reset_dictionaries()\n",
    "    return score, episode, traj_score, eff_score, scenario_name,history"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "234278e488672735"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "a = [1,2,3,4,5]\n",
    "a[-1:-6:-1]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "65ba22fe5caebd52"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def evaluate_episode_choose(chooser, topk, agent, env, policy=\"softmax\",prev_exp=None,summarizer=None):\n",
    "    episode = []\n",
    "    step = 0\n",
    "    score = 0\n",
    "    done = False\n",
    "    agent.reset_dictionaries()\n",
    "    history = []\n",
    "    reasons = []\n",
    "    ob, valid_acts, hc = env.reset()\n",
    "\n",
    "    history.append(ob[1])\n",
    "    scenario_name = env.scenario[\"name\"]\n",
    "    subject = env.scenario[\"characters\"][0]\n",
    "    problem = find_phrase(ob[1])[0]\n",
    "    state = agent.create_state(update_sentence=ob, hc=hc)\n",
    "    posttest = False\n",
    "    while not done:\n",
    "        transition = [env.scenario[\"name\"], step, ob[1], ]\n",
    "        valid_ids = agent.encode_actions(valid_acts)\n",
    "        _, action_idx, action_values, _ = agent.act(\n",
    "            [state], [valid_ids], policy=policy, eval_mode=True, action_strs=valid_acts, temperature= 1)\n",
    "        sorted_idxs = np.argsort(action_values[0].detach().cpu().numpy())\n",
    "        if not posttest:\n",
    "            choices_idxs = sorted_idxs[-1:-topk-1:-1]\n",
    "        else:\n",
    "            choices_idxs = sorted_idxs[-1:-3:-1]\n",
    "        choices = [valid_acts[i][\"sentence\"] for i in choices_idxs]\n",
    "        print(choices)\n",
    "        if len(valid_acts)>1:\n",
    "            is_valid = False\n",
    "            tries = 0\n",
    "            while not is_valid:\n",
    "                tries += 1\n",
    "                if not is_valid and tries>3:\n",
    "                    print(choices)\n",
    "                    print(chosen_action)\n",
    "                    print(reason)\n",
    "                    print('Out of tries')\n",
    "                    chosen_action = 1\n",
    "                    break\n",
    "\n",
    "                response = chooser.choose(history, subject, problem, choices, posttest=posttest,prev_exp=prev_exp)\n",
    "                try:\n",
    "                    reason,chosen_action = response.split(\"###\")\n",
    "                except Exception as e:\n",
    "\n",
    "                    print(e)\n",
    "                    print(response)\n",
    "                    continue\n",
    "                reason,chosen_action = reason.strip(\"\\n\").strip(),chosen_action.strip(\"\\n\").strip()\n",
    "                if chosen_action.isnumeric():\n",
    "                    chosen_action = int(chosen_action)\n",
    "                    reason = reason.split(\": \")[-1]\n",
    "                    if chosen_action<=len(choices_idxs) and chosen_action>0:\n",
    "                        chosen_action = chosen_action\n",
    "                        reason = reason\n",
    "                        is_valid = True\n",
    "\n",
    "\n",
    "            reasons.append(reason)\n",
    "            print(chosen_action)\n",
    "            print(reason)\n",
    "        else:\n",
    "            chosen_action = 1\n",
    "        action_str = (valid_acts[choices_idxs[chosen_action-1]])\n",
    "        history.append(action_str[\"sentence\"])\n",
    "        state_update, rew, done, valid_acts, hc, traj_score = env.step(ob, action_str)\n",
    "        if not done:\n",
    "            if state_update[0] == \"interaction\":\n",
    "                history.append(\".\".join(state_update[1].split(\".\")[2:]))\n",
    "            else:\n",
    "                history.append(\".\".join(state_update[1].split(\".\")[-1:]))\n",
    "        posttest = state_update[0] == \"posttest\"\n",
    "        if not done:\n",
    "            trace = env.trace\n",
    "        ob = state_update\n",
    "        score += rew\n",
    "        step += 1\n",
    "        transition += [action_str, rew, score]\n",
    "        episode.append(transition)\n",
    "        state = agent.create_state(\n",
    "            update_sentence=ob, hc=hc, previous_state=state)\n",
    "    traj_score = sum(\n",
    "        a in trace for a in env.scenario[\"present_actions\"]) / len(env.scenario[\"present_actions\"])\n",
    "    eff_score = sum(\n",
    "        a in trace for a in env.scenario[\"present_actions\"]) / len(trace)\n",
    "    agent.reset_dictionaries()\n",
    "    return score, episode, traj_score, eff_score, scenario_name,history"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "15f52325dfe7c9b4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def evaluate_episode_choose_or_rec(cor, topk, agent, env, policy=\"softmax\",prev_exp=None,summarizer=None):\n",
    "    episode = []\n",
    "    step = 0\n",
    "    score = 0\n",
    "    done = False\n",
    "    agent.reset_dictionaries()\n",
    "    valid_subjects = env.scenario[\"subjects\"]\n",
    "    valid_topics = env.scenario[\"topics\"]\n",
    "    valid_causes = env.scenario[\"causes\"]\n",
    "    scenario_name = env.scenario[\"name\"]\n",
    "    history = []\n",
    "    reasons = []\n",
    "    ob, valid_acts, hc = env.reset()\n",
    "\n",
    "    history.append(ob[1])\n",
    "    scenario_name = env.scenario[\"name\"]\n",
    "    subject = env.scenario[\"characters\"][0]\n",
    "    problem = find_phrase(ob[1])[0]\n",
    "    state = agent.create_state(update_sentence=ob, hc=hc)\n",
    "    posttest = False\n",
    "    while not done:\n",
    "        transition = [env.scenario[\"name\"], step, ob[1], ]\n",
    "        valid_ids = agent.encode_actions(valid_acts)\n",
    "        _, action_idx, action_values, _ = agent.act(\n",
    "            [state], [valid_ids], policy=policy, eval_mode=True, action_strs=valid_acts, temperature= 1)\n",
    "        sorted_idxs = np.argsort(action_values[0].detach().cpu().numpy())\n",
    "        choices_idxs = sorted_idxs[-1:-topk-1:-1]\n",
    "        choices = [valid_acts[i][\"sentence\"] for i in choices_idxs]\n",
    "        print(choices)\n",
    "        if len(valid_acts)>1:\n",
    "            is_valid = False\n",
    "            tries = 0\n",
    "            while not is_valid:\n",
    "                tries += 1\n",
    "                response = cor.cor(history, subject, problem, valid_subjects, valid_topics, valid_causes, choices, posttest=posttest,prev_exp=prev_exp)\n",
    "                try:\n",
    "                    mode,response = response.split(\"$$$\")\n",
    "                except Exception as e:\n",
    "                    print(e)\n",
    "                    print(response)\n",
    "                    continue\n",
    "                mode = mode.strip(\"\\n\").strip()\n",
    "                if mode == \"choose\":\n",
    "                    try:\n",
    "                        reason,chosen_action = response.split(\"###\")\n",
    "                    except Exception as e:\n",
    "                        print(e)\n",
    "                        print(response)\n",
    "                        continue\n",
    "                    reason,chosen_action = reason.strip(\"\\n\").strip(),chosen_action.strip(\"\\n\").strip()\n",
    "                    if chosen_action.isnumeric():\n",
    "                        chosen_action = int(chosen_action)\n",
    "                        reason = reason.split(\": \")[-1]\n",
    "                        is_valid = True\n",
    "                    if not is_valid and tries>3:\n",
    "                        print(choices)\n",
    "                        print(chosen_action)\n",
    "                        print(reason)\n",
    "                        print('Out of tries')\n",
    "                        chosen_action = choices_idxs[0]\n",
    "                else:\n",
    "                    reason,recs = response.split(\"###\")\n",
    "                    reason,recs = reason.strip(\"\\n\").strip(),recs.strip(\"\\n\").strip()\n",
    "\n",
    "                    parsed_responses = []\n",
    "                    for x in recs.split(\"\\n\"):\n",
    "                        parsed_responses.append(parse_string_to_dict((x.split(\". \")[-1]),valid_subjects,valid_topics,valid_causes,replace_closest=tries>3))\n",
    "                    recs_idxs = []\n",
    "                    valid_responses = []\n",
    "                    for x in parsed_responses:\n",
    "                        if x in valid_acts:\n",
    "                            recs_idxs.append(valid_acts.index(x))\n",
    "                            valid_responses.append(valid_acts[recs_idxs[-1]])\n",
    "\n",
    "                    if len(recs_idxs)>0:\n",
    "                        is_valid = True\n",
    "                        act_probs = (softmax(action_values[0][recs_idxs],temperature=0.001 if posttest else 1))\n",
    "                        chosen_act_idx = torch.multinomial(act_probs, num_samples=1).item()\n",
    "                        print(reason, recs)\n",
    "                        action_str = valid_responses[chosen_act_idx]\n",
    "                        print(action_str)\n",
    "                    if not is_valid and tries>3:\n",
    "                        print(\"OUT OF TRIES\")\n",
    "                        break\n",
    "\n",
    "            reasons.append(reason)\n",
    "            print(chosen_action)\n",
    "            print(reason)\n",
    "        else:\n",
    "            chosen_action = 1\n",
    "        action_str = (valid_acts[choices_idxs[chosen_action-1]])\n",
    "        history.append(action_str[\"sentence\"])\n",
    "        state_update, rew, done, valid_acts, hc, traj_score = env.step(ob, action_str)\n",
    "        if not done:\n",
    "            if state_update[0] == \"interaction\":\n",
    "                history.append(\".\".join(state_update[1].split(\".\")[2:]))\n",
    "            else:\n",
    "                history.append(\".\".join(state_update[1].split(\".\")[-1:]))\n",
    "        posttest = state_update[0] == \"posttest\"\n",
    "        if not done:\n",
    "            trace = env.trace\n",
    "        ob = state_update\n",
    "        score += rew\n",
    "        step += 1\n",
    "        transition += [action_str, rew, score]\n",
    "        episode.append(transition)\n",
    "        state = agent.create_state(\n",
    "            update_sentence=ob, hc=hc, previous_state=state)\n",
    "    traj_score = sum(\n",
    "        a in trace for a in env.scenario[\"present_actions\"]) / len(env.scenario[\"present_actions\"])\n",
    "    eff_score = sum(\n",
    "        a in trace for a in env.scenario[\"present_actions\"]) / len(trace)\n",
    "    agent.reset_dictionaries()\n",
    "    return score, episode, traj_score, eff_score, scenario_name,history"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f4c198480bae5f2e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def rename_folder(old_name, new_name):\n",
    "    try:\n",
    "        os.rename(old_name, new_name)\n",
    "        print(f\"Folder '{old_name}' renamed to '{new_name}' successfully.\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Folder '{old_name}' not found.\")\n",
    "    except FileExistsError:\n",
    "        print(f\"Folder '{new_name}' already exists.\")\n",
    "def remove_folder(folder_path):\n",
    "    try:\n",
    "        shutil.rmtree(folder_path)\n",
    "        print(f\"Folder '{folder_path}' removed successfully.\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Folder '{folder_path}' not found.\")\n",
    "    except PermissionError:\n",
    "        print(f\"Permission denied to remove folder '{folder_path}'.\")\n",
    "def copy_folder(source_folder, destination_folder):\n",
    "    try:\n",
    "        # Check if the destination folder exists, and if not, create it\n",
    "        if os.path.exists(destination_folder):\n",
    "            shutil.rmtree(destination_folder)\n",
    "            print(f\"Deleted folder '{destination_folder}'.\")\n",
    "\n",
    "        # Copy the source folder and its contents to the destination folder\n",
    "        shutil.copytree(source_folder, destination_folder)\n",
    "        print(f\"Folder '{source_folder}' copied to '{destination_folder}' successfully.\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Folder '{source_folder}' not found.\")\n",
    "    except FileExistsError:\n",
    "        print(f\"Folder '{destination_folder}' already exists.\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "132e177bbf48dad0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def print_table(scores):\n",
    "    # Headers for the table\n",
    "    print(f\"{'Mode/Type':<15}{'Choose':<20}{'Recommend':<20} {'Normal':<20}\")\n",
    "\n",
    "    for mode in ['train', 'val', 'test']:\n",
    "        print(f\"{mode:<15}\", end='')\n",
    "\n",
    "        for typ in ['choose','recomend', 'normal']:\n",
    "            score, traj_score = scores[typ][mode][\"score\"], scores[typ][mode][\"traj_score\"]\n",
    "            print(f\"{score}/{traj_score:<20}\", end='')\n",
    "\n",
    "        print()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "388b2a4acbb19d15"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def softmax(q_values, temperature):\n",
    "    \"\"\"\n",
    "    Apply softmax function with temperature to a set of Q-values.\n",
    "\n",
    "    :param q_values: A tensor of Q-values for each action.\n",
    "    :param temperature: The temperature parameter for softmax.\n",
    "                        Higher values increase exploration.\n",
    "    :return: The probabilities for each action.\n",
    "    \"\"\"\n",
    "    q_values_temp = q_values / temperature\n",
    "    exp_q_values = torch.exp(q_values_temp - torch.max(q_values_temp))\n",
    "    probabilities = exp_q_values / torch.sum(exp_q_values)\n",
    "\n",
    "    return probabilities"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cdd2077a5c5dd9eb"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fasttext_model = fasttext.load_model(\n",
    "                \"./lms/cc.en.300.bin\"\n",
    "            )\n",
    "def find_all_occurences(list, value):\n",
    "    return [i for i, x in enumerate(list) if x == value]\n",
    "def match(sentence, valid_sentences,replace_closest=False):\n",
    "    for t in valid_sentences:\n",
    "        if sentence == t.lower():\n",
    "            return t\n",
    "    indicator = [(sentence in t.lower()) or (t.lower() in sentence) for t in valid_sentences]\n",
    "    if any(indicator):\n",
    "        idx = find_all_occurences(indicator,True)\n",
    "        values = [valid_sentences[i] for i in idx]\n",
    "        len_values = [len(x) for x in values]\n",
    "        if len(idx)>1:\n",
    "            idx = idx[len_values.index(max(len_values))]\n",
    "        if isinstance(idx,list):\n",
    "            idx = idx[0]\n",
    "        return valid_sentences[idx]\n",
    "    else:\n",
    "        if replace_closest:\n",
    "            ### replace the closest sentence\n",
    "            valid_sentences_embeddings = [fasttext_model.get_sentence_vector(x) for x in valid_sentences]\n",
    "            sentence_embedding = fasttext_model.get_sentence_vector(sentence)\n",
    "            distances = [1-scipy.spatial.distance.cosine(x,sentence_embedding) for x in valid_sentences_embeddings]\n",
    "            idx = distances.index(max(distances))\n",
    "            return valid_sentences[idx]\n",
    "        else:\n",
    "            return sentence\n",
    "def parse_string_to_dict(input_str,valid_subjects,valid_topics,valid_causes,replace_closest=False):\n",
    "    # Splitting the input string into the command and the arguments\n",
    "    input_str = input_str.lower()\n",
    "    print(input_str)\n",
    "    parts = input_str.split('(',1)\n",
    "    command = parts[0]\n",
    "    args = parts[1].rsplit(')',1)[0] if len(parts) > 1 else \"\"\n",
    "    args = args.split(\"),\")[0]\n",
    "    # Initializing the dictionary with default values\n",
    "    result_dict = {\n",
    "        \"type\": \"\",\n",
    "        \"part\": \"\",\n",
    "        \"detail\": \"\",\n",
    "        \"sentence\": \"\"\n",
    "    }\n",
    "\n",
    "    # Mapping based on the command\n",
    "    if command == \"ask\":\n",
    "        result_dict[\"type\"] = \"interaction\"\n",
    "        result_dict[\"part\"] = \"discuss\"\n",
    "        if len(args.split(',')) != 2:\n",
    "            print(args.split(','))\n",
    "            raise\n",
    "        subject, topic = args.split(',') if args else (\"\", \"\")\n",
    "        subject, topic = subject.strip(), topic.strip()\n",
    "        subject = match(subject,valid_subjects,replace_closest=replace_closest)\n",
    "        topic = match(topic,valid_topics,replace_closest=replace_closest)\n",
    "        print(subject,topic)\n",
    "        result_dict[\"detail\"] = \",\".join([subject,topic])\n",
    "        result_dict[\"sentence\"] = f\"i want to know about the {subject} 's {topic}.\"\n",
    "\n",
    "    elif command == \"answer\":\n",
    "        result_dict[\"type\"] = \"interaction\"\n",
    "        result_dict[\"part\"] = \"solution\"\n",
    "        result_dict[\"sentence\"] = \"i want to suggest a solution.\"\n",
    "\n",
    "    elif command == \"choose\":\n",
    "        result_dict[\"type\"] = \"posttest\"\n",
    "        args = match(args,valid_causes,replace_closest=replace_closest)\n",
    "        result_dict[\"sentence\"] = args\n",
    "\n",
    "    return result_dict\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c0a58cbcfc9e5233"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def find_phrase(text):\n",
    "    # Pattern to find phrases between \"have\"/\"has\" and a dot\n",
    "    pattern = r'\\b(have|has)\\b(.*?)(?=\\.)'\n",
    "\n",
    "    # Find all matches in the text\n",
    "    matches = re.findall(pattern, text, re.IGNORECASE | re.DOTALL)\n",
    "\n",
    "    # Extracting the phrases\n",
    "    phrases = [''.join(match[1]).strip() for match in matches]\n",
    "    return phrases"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b89cac27b3162945"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "4129286fc3a6240"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "eval_modes = [\"wording\"]\n",
    "# eval_modes = [\"wording\",]\n",
    "inferences = [\"choose\",\"recommend\",\"play\",\"normal\",\"clin_choose\",\"clin_recommend\",\"clin_play\"]\n",
    "inferences = [\"normal\",\"recommend\",\"clin_recommend\",\"choose\",\"clin_choose\",\"normal\"]\n",
    "# inferences = [\"normal\"]\n",
    "# inferences = [\"clin_play\"]\n",
    "inferences = [\"clin_play\",\"clin_recommend\",\"clin_choose\"]\n",
    "# inferences = [\"normal\"]\n",
    "patients = [\"baby\",\"mother\",\"gm\",\"skin\",\"eye\",\"gyno\",\"joint\",\"stomachache\",\"throat\"]\n",
    "# patients = [\"mother\",\"eye\",\"gm\"]\n",
    "# patients = [\"baby\",\"skin\",\"gyno\",\"joint\",\"stomachache\",\"throat\"]\n",
    "# patients = [\"throat\"]\n",
    "# patients = [\"baby\"]\n",
    "modes = [\"train\",\"val\",\"test\"]\n",
    "modes = [\"test\"]\n",
    "splits = [0,1,2]\n",
    "splits = [0]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "faa1b71e16a1c2b0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for e in eval_modes:\n",
    "    for p in patients:\n",
    "        for inference in inferences:\n",
    "            for mode in modes:\n",
    "                for split in splits:\n",
    "                    print(f\"Patient: {p}, Eval mode: {e}, Inference: {inference}, Mode: {mode}, Split: {split}\")\n",
    "                    evaluate_patient_eval_mode(p, e, inference, mode_=mode,split=split)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9750b1c3a480232b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "################### DOWNLOAD MODELS ####################\n",
    "run = wandb.init()\n",
    "for split in splits:\n",
    "    for p in patients:\n",
    "        for e in eval_modes:\n",
    "            if os.path.exists(f\"./models/{p}_{e}_{split}\"):\n",
    "                print(f\"Folder './models/{p}_{e}_{split}' already exists.\")\n",
    "            else:\n",
    "                print(f\"Downloading {p}_{e} models\")\n",
    "                artifact = run.use_artifact(f'xxxx/{p}_{e}_not_pretrained_fasttext_cause_sum/best-model:latest', type='model')\n",
    "                artifact_dir = artifact.download()\n",
    "                rename_folder(artifact_dir, f\"./models/{p}_{e}_{split}\")\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3054e3838404fd11"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "################### SPLIT SCENARIOS ####################\n",
    "for e in eval_modes:\n",
    "    remove_folder(os.path.join(config[\"game_path\"],e))\n",
    "    for p in patients:\n",
    "        dirs = [\"train\", \"val\", \"test\"]\n",
    "        for d in dirs:\n",
    "            for f in os.listdir(os.path.join(config[\"game_path\"], \"patients\",p,e,d)):\n",
    "                json_file = os.path.join(config[\"game_path\"], \"patients\",p,e,d,f)\n",
    "                if os.path.isfile(json_file):\n",
    "                    with open(json_file, \"r\") as file:\n",
    "                        scenario = json.load(file)\n",
    "                        if len(scenario[\"subjects\"])<3:\n",
    "                            scenario[\"subjects\"] = list(scenario[\"question_answers\"].keys())\n",
    "                            json.dump(scenario, open(json_file, \"w\"), indent=4, sort_keys=True)\n",
    "            copy_folder(os.path.join(config[\"game_path\"], \"patients\",p,e,d), os.path.join(config[\"game_path\"],e,p,d,\"0\"))\n",
    "            # copy_folder(os.path.join(config[\"game_path\"], \"patients\",p,e,d), os.path.join(config[\"game_path\"],e,p,d))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "71d9723cfdd26d30"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "################### SPLIT SCENARIOS ####################\n",
    "for e in eval_modes:\n",
    "    remove_folder(os.path.join(config[\"game_path\"],e))\n",
    "    for p in patients:\n",
    "        dirs = [\"train\", \"val\", \"test\"]\n",
    "        for d in dirs:\n",
    "            for f in os.listdir(os.path.join(config[\"game_path\"], \"patients\",p,e,d)):\n",
    "                json_file = os.path.join(config[\"game_path\"], \"patients\",p,e,d,f)\n",
    "                if os.path.isfile(json_file):\n",
    "                    with open(json_file, \"r\") as file:\n",
    "                        scenario = json.load(file)\n",
    "                        if len(scenario[\"subjects\"])<3:\n",
    "                            scenario[\"subjects\"] = list(scenario[\"question_answers\"].keys())\n",
    "                            json.dump(scenario, open(json_file, \"w\"), indent=4, sort_keys=True)\n",
    "            copy_folder(os.path.join(config[\"game_path\"], \"patients\",p,e,d), os.path.join(config[\"game_path\"],e,p,d))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e1a94e7e754aef5b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for e in eval_modes:\n",
    "    for p in patients:\n",
    "        for inference in inferences:\n",
    "            for mode in modes:\n",
    "                for split in splits:\n",
    "                    print(f\"Patient: {p}, Eval mode: {e}, Inference: {inference}, Mode: {mode}, Split: {split}\")\n",
    "                    evaluate_patient_eval_mode(p, e, inference, mode_=mode,split=split)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d43e91803eb046f5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "\n",
    "# Assuming eval_modes, patients, and inferences are defined lists\n",
    "# and evaluate_patient_eval_mode is a function you've defined\n",
    "\n",
    "# Define a wrapper function for your task\n",
    "def process_task(e, p, inference,mode, split):\n",
    "    print(f\"Patient: {p}, Eval mode: {e}, Inference: {inference}, Mode: {mode}, Split: {split}\")\n",
    "    evaluate_patient_eval_mode(p, e, inference, mode_=mode,split=split)  # Assuming 'modes' is defined elsewhere\n",
    "\n",
    "# Create a list of all task arguments\n",
    "tasks = [(e, p, inference,mode,split) for e in eval_modes for p in patients for inference in inferences for mode in modes for split in splits]\n",
    "\n",
    "# Use ThreadPoolExecutor or ProcessPoolExecutor to run tasks in parallel\n",
    "# Adjust max_workers based on your system's capabilities and the nature of your tasks\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=2) as executor:\n",
    "    # Submit all tasks to the executor\n",
    "    future_to_task = {executor.submit(process_task, *task): task for task in tasks}\n",
    "\n",
    "    # Process the results as they complete (optional)\n",
    "    for future in concurrent.futures.as_completed(future_to_task):\n",
    "        task = future_to_task[future]\n",
    "        try:\n",
    "            result = future.result()  # You can use the result if your function returns something\n",
    "        except Exception as exc:\n",
    "            print(f\"Task {task} generated an exception: {exc}\")\n",
    "        else:\n",
    "            print(f\"Task {task} completed successfully.\")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f93672eeecefadeb"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
